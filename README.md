<p align="center">
      <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Amazon-S3-Logo.svg/1712px-Amazon-S3-Logo.svg.png" width="250" height="250">
</p>

<p align="center">
   <img alt="Python" src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54">
</p>

## О проекте

Данная система предназначена для создания тестовой нагрузки на хранилища, которые работают по совместимому S3 протоколу.

## Основные возможности системы

1. Заполнение хранилища случайными данными указанного размера
2. Удаление всех данных из хранилища
3. Получение статистики по количеству операций в секунду, текущей загруженности хранилища (объем и количество объектов), отчет о количестве успешных и неудачных загрузок/удалений объектов

## Инструкция пользователя

Процесс создания тестовой нагрузки на систему состоит из следующих этапов:
1. Запрос на создание файлов указанного размера со случайным содержимым. Необходимо запустить <b>main.py</b> и указать необходимые данные. После этого БД PostreSQL будет заполнена необходимой служебной информацией
2. Отправка данных о файлах, которые необходимо загрузить. Необходимо запустить <b>kafka/producer.py</b> и дождаться отправки всех данных в очередь Kafka
3. Загрузка и удаление объектов в/из хранилища S3. Необходимо запустить <b>worker/Worker.py</b> и выбрать необходимый пункт в интерактивном меню

## Установка всех зависимостей и модулей для работы системы

Для функционирования системы используются следующие компоненты:
1. База данных PostgreSQL
2. Брокер сообщений (очередь) Kafka
3. Само хранилище S3 (для тестов использовалось локальное хранилище MinIO)
4. Prometheus и Grafana для сбора и графического отображения статистики
5. Python с установленным набором библиотек (см. далее)

Подробнее о том, как подключить все необходимые модули:

1. Для создания таблицы в БД PostgreSQL необходимо запустить скрипт создания таблицы <b>database/create_db.sql</b>, затем указать данные для подключения к БД в файле конфигурации <b>database/db_config.py</b>
2. Для запуска Kafka нужно запускать команды последовательно в разных терминалах:<br>
   <code>bin/zookeeper-server-start.sh config/zookeeper.properties
   bin/kafka-server-start.sh config/server.properties
   bin/kafka-topics.sh --create --topic topic-demo --bootstrap-server localhost:9092
   bin/kafka-topics.sh --alter --topic topic-demo --partitions 4 --bootstrap-server localhost:9092
   </code>
   Где <b>topic-demo</b> -  это название топика, куда будут отправляться сообщения, а <b>--partitions 4</b> - количество потоков (слушателей), которые будут обрабатывать сообщения
3. [Опционально] Если вы хотите проводить тестирование системы локально, то можно запустить MinIO следующей командой: <code>minio server /path/to/log_file</code>
4. Необоходимо установить Prometheus и Grafana. В конфигурационном файле <b>prometheus.yml</b> прописать следующее:<br>
   <code>global:
     scrape_interval: 15s
   scrape_configs:
     - job_name: 'python-app'
        static_configs:
          - targets: ['localhost:8000']</code><br>
    После этого применить дашборд для отображения статистики в Grafana из <b>grafana/dashboard.json</b>
5. Для запуска системы необходимо установить все зависимости для Python, применив команду, находясь в корне проекта: <code>pip install -r requirements.txt</code>

## Разработчики

- [Владимир Быков](https://github.com/Voviihb)
- [Полина Рыморенко](https://github.com/PolinaRym)
